{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257afda2-9e10-49b6-b185-f2ed42757b8f",
   "metadata": {},
   "source": [
    "###### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309721a1-f29b-44de-9653-faa9da8032e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1+cu118\n",
      "tiktoken version: 0.8.0\n",
      "mlPLayGround version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "ver = lambda libstr: print(f'{libstr} version: {version(libstr)}')\n",
    "ver(\"torch\")\n",
    "ver(\"tiktoken\")\n",
    "ver(\"mlPLayGround\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dc96c1-8af1-4421-bc57-4096e0f36690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from mlPlayGround.recurrent.attention import multiHeadAttention, multiHeadAttentionTorch, multiHeadAttentionTorchSDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d9613e-f26f-4b41-a529-0bb11894e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53544cfb-7d13-4565-9d86-9d00be916cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "context_len = 1024\n",
    "embed_dim = 768\n",
    "n_heads = 12\n",
    "dropout = 0.0\n",
    "bias = False\n",
    "\n",
    "embeddings = torch.randn((batch_size, context_len, embed_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc10a14e-50ba-4c16-a145-8993c59eeb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.1 ms ± 120 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "mha = multiHeadAttention(embed_dim, embed_dim, n_heads,\n",
    "                         context_len, dropout, bias).to(device)\n",
    "# print(mha(embeddings).shape)\n",
    "%timeit mha(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a92e790-69ac-486f-a91c-5698d626fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 ms ± 30.1 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "mha = multiHeadAttentionTorch(embed_dim, embed_dim, n_heads,\n",
    "                              context_len, dropout, bias, False).to(device)\n",
    "# print(mha(embeddings).shape)\n",
    "%timeit mha(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7550487a-58d6-4a76-9fd8-5d3c68c00659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.5 ms ± 112 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "mha = multiHeadAttentionTorch(embed_dim, embed_dim, n_heads,\n",
    "                              context_len, dropout, bias, True).to(device)\n",
    "# print(mha(embeddings).shape)\n",
    "%timeit mha(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f64de81-72eb-431e-b2df-62d1033449b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.4 ms ± 26.6 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "mha = multiHeadAttentionTorchSDP(embed_dim, embed_dim, n_heads,\n",
    "                                 context_len, dropout, bias).to(device)\n",
    "# print(mha(embeddings).shape)\n",
    "%timeit mha(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fcb30c-602e-4442-b9e6-16df0127c078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19)\n",
      "(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95)\n"
     ]
    }
   ],
   "source": [
    "a, b = zip(*[(i, 5*i) for i in range(20)])\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd99890-aed5-496d-9495-c1a3759ba7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ec662-d317-412c-9257-ed55d5559d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c69cfc2-cf10-4547-b6fa-f58dc78d448b",
   "metadata": {},
   "source": [
    "##### Buildin an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7cc82a-825d-49c4-b866-7ecdac73bd25",
   "metadata": {},
   "source": [
    "###### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0648efd5-8aab-4b67-825e-469d3d07ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "fname = \"../data/llmbuild/the-verdict.txt\"\n",
    "if not os.path.exists(fname):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da0cbc-5d29-468e-b3a4-62ae1c415118",
   "metadata": {},
   "source": [
    "We would like to tokenize and embed the bove test. To begin we create a simple tokenizer using some sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "081fa0c8-662b-4652-9e96-013a0e71fdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Bytepair encoding using tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens = tokenizer.encode(raw_text)\n",
    "print(tokenizer.decode(tokens) == raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ee9b43d-7ec1-4e63-a67f-6a77534ad72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5) # dropout rate of 50%\n",
    "example = torch.ones(6, 6) # create a matrix of ones\n",
    "\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d92e943-3d69-49b8-ac22-727442fc55c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96bc62ff-ea29-4143-bb5f-59c2fc8efe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.)\n",
      "tensor(36.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum(example))\n",
    "print(torch.sum(dropout(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1f4f6-ab72-4e50-ab02-ec35ad41271e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689a2a2-04c2-4b70-b85a-a60028f279bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "248276bb-fd75-4229-a79d-f28e2d72ca97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = [item for item in re.split(r'([,.:;?_!\"()\\']|--|\\s)', text) if item.strip()] # re and ignore empty strings\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5404476-f799-4172-bd27-b11455c44ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "preproc = [item for item in re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text) if item.strip()] # re and ignore empty strings\n",
    "print(len(preproc))\n",
    "print(preproc[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae19b9a-9eb4-402d-bea5-a6a3090ebdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "# get unique tokens\n",
    "all_tokens = sorted(set(preproc))\n",
    "vocab_size = len(all_tokens)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "014c5798-f281-4b67-9c7d-7b545d83e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {t:i for i, t in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746a74d-dd67-4c40-a82c-db4a4636ff46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3ce3084-ad28-40ed-89ec-4ed47c0f9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c79e7-590d-442a-a602-144393ef9eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f37f43-9b84-4aed-b9e2-4a3f835a3445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab4eed-0869-4de1-85c0-c8305c8de872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c644a986-48b1-46b4-8850-07e0613c65ee",
   "metadata": {},
   "source": [
    "TODO: how do audio and video embeddings work?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
